{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f3110f",
   "metadata": {},
   "source": [
    "### <b>The SPKF Steps</b>\n",
    "$\\begin{array}{lccccc}\n",
    "\\hline\\rule{0pt}{3.5ex} \\text { Method } & \\gamma & \\alpha_0^{(\\mathrm{m})} & \\alpha_k^{(\\mathrm{m})} & \\alpha_0^{(\\mathrm{c})} & \\alpha_k^{(\\mathrm{c})} \\\\\n",
    "\\text { CDKF } & h & \\frac{h^2-L}{h^2} & \\frac{1}{2 h^2} & \\frac{h^2-L}{h^2} & \\frac{1}{2 h^2}\\rule[-2ex]{0pt}{5ex}\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\\\$\n",
    "$_{\\quad {}^*h \\text{ may take any positive value. For Gaussian RVs, } h = \\sqrt{3}}\\\\\\quad{_{L\\text{ is the \n",
    "dimension of state space vector }x}}$\n",
    "### <b>SPKF step 1a:</b> State estimate time update.\n",
    "\n",
    "- Augmented aposteriori state estimate vector for previous time interval :\n",
    "\n",
    "$\\quad \\hat{\\chi}{^{a,+}_{k-1}}=\\begin{bmatrix}{\\hat{\\chi}{^+_{k-1}}},&{\\bar{w}},&{\\bar{v}}\\end{bmatrix}$<br><br>\n",
    "- Augmented aposteriori state covariance estimate vector for previous time interval:\n",
    "\n",
    "$\\quad\\sum{^{a,+}_{\\tilde{x},k-1}}=\\mathrm{diag}({\\sum{^{+}_{\\tilde{x},k-1}}},\\sum{\\tilde{w}},\\sum{\\tilde{v}})$<br><br>\n",
    "- To generate the p+1 augmented sigma points\n",
    "\n",
    "$\\quad\\chi{^{a,+}_{k-1}}=\\left\\{{\\hat{\\chi}{^{a,+}_{k-1}}},\\quad\\hat{\\chi}{^{a,+}_{k-1}}+\\gamma\\sqrt{\\sum\n",
    "{^{a,+}_{\\tilde{x},k-1}}},\\quad\\hat{\\chi}{^{a,+}_{k-1}}-\\gamma\\sqrt{\\sum{^{a,+}_{\\tilde{x},k-1}}}\\right\\}\\\\ \\quad \\rule[-1.5ex]{0pt}{4.5ex}\n",
    "\\mathcal{X}_{k, i}^{x,-}=f\\left(\\mathcal{X}_{k-1, i}^{x,+}, u_{k-1}, \\mathcal{X}_{k-1, i}^{w,+}\\right)\n",
    "$\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\quad\\hat{x}_k^{-} & =\\mathbb{E}\\left[f\\left(x_{k-1}, u_{k-1}, w_{k-1}\\right) \\mid \\mathbb{Y}_{k-1}\\right]\n",
    " \\approx \\sum_{i=0}^p \\alpha_i^{(\\mathrm{m})} f\\left(\\mathcal{X}_{k-1, i}^{x,+}, u_{k-1}, \\mathcal{X}_\n",
    " {k-1, i}^{w,+}\\right)\n",
    " =\\sum_{i=0}^p \\alpha_i^{(\\mathrm{m})} \\mathcal{X}_{k, i}^{x,-}\n",
    "\\end{aligned}\n",
    "$\n",
    "### <b>SPKF step 1b:</b> Error covariance time update.\n",
    "\n",
    "- Using the *apriori* sigma points from step 1a, the *apriori* covariance\n",
    "estimate is computed as :\n",
    "\n",
    "$\\quad\\large{{\\Sigma}^{-}_{\\tilde{x},k} = \\sum_{i=0}^{p} \\alpha_i^{(c)} (\\mathcal{X}_{k,i}^{x,-} - \\hat{x}\n",
    "_k^{-}) (\\mathcal{X}_{k,i}^{x,-} - \\hat{x}_k^{-})^T\n",
    "}$\n",
    "### <b>SPKF step 1c:</b> Estimate system output $y_k$.\n",
    "- First, we compute the points :\n",
    "\n",
    "$\\quad\n",
    "\\mathcal{Y}_{k,i} = h(\\mathcal{X}_{k,i}^{x,-}, u_k, \\mathcal{X}_{k-1,i}^{v,+})\n",
    "$\n",
    "- The output estimate is then\n",
    "\n",
    "$\\quad\n",
    "\\hat{y}_k = \\mathbb{E}[h(x_k, u_k, v_k) \\mid \\mathbb{Y}_{k-1}] \\approx \\sum_{i=0}^{p} \\alpha_i^{(m)} h(\\mathcal{X}_{k,i}^x, u_k, \\mathcal{X}_{k-1,i}^{v,+}) = \\sum_{i=0}^{p} \\alpha_i^{(m)} \\mathcal{Y}_{k,i}.\n",
    "$\n",
    "### <b>SPKF step 2a:</b> Estimator gain matrix $L_k$\n",
    "- To compute the estimator gain matrix, we must first compute the\n",
    "required covariance matrices.\n",
    "\n",
    "$\\large{\\quad\n",
    "\\Sigma_{\\tilde{y} , k}=\\sum_{i=0}^{p} \\alpha_{i}^{( \\mathrm{c} )} \\big( \\mathcal{Y}_{k , i}-\\hat{y}_{k} \\big) \\big( \\mathcal{Y}_{k , i}-\\hat{y}_{k} \\big)^{T}}\\\\\n",
    "\\rule[-.5ex]{0pt}{3ex}\n",
    "\\large{\\quad\n",
    "\\Sigma_{\\tilde{x} \\tilde{y} , k}^{-}=\\sum_{i=0}^{p} \\alpha_{i}^{( \\mathrm{c} )} \\big( \\mathcal{X}_{k , i}^{x ,-}-\\hat{x}_{k}^{-} \\big) \\big( \\mathcal{Y}_{k , i}-\\hat{y}_{k} \\big)^{T}}$\n",
    "\n",
    "- Then, we simply compute $L_k=\\sum^-_{\\tilde{x}\\tilde{y},k}\\sum^{-1}_{\\tilde{y},k}$\n",
    "\n",
    "### <b>SPKF step 2b:</b> State estimate measurement update.\n",
    "- The state estimate is computed as\n",
    "\n",
    "$\\quad\\hat{x}^+_k=\\hat{x}^-_k+L_k{(y_k-\\hat{y}_k)}$\n",
    "\n",
    "### <b>SPKF step 2c:</b> Error covariance measurement update.\n",
    "- The final step is calculated directly from the optimal formulation:\n",
    "\n",
    "$\\large\\quad\\sum{^{+}_{\\tilde{x},k}}=\\sum_{\\tilde{x},k}^--L_k\\sum_{\\tilde{y},k}L_k^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb3612",
   "metadata": {},
   "source": [
    "<h3><center>State and Measurement equation for the UKF example ...</center></h3>\n",
    "\n",
    "$$ x_{k+1} = \\sqrt{x_k + 5} + w_k $$\n",
    "$$ y_k = x_k^3 + v_k $$\n",
    "$$ \\sum\\tilde{x}_{\\mathrm{true}}=1\\sum{\\tilde{w}}=0.1 \\sum{\\tilde{v}}=0.1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee9c417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.linalg import cholesky, inv, sqrtm, block_diag\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "881d9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx=1 # Number of states\n",
    "Nxa=3 # Augmented number of states\n",
    "Ny=1 # Number of measurements\n",
    "h=np.sqrt(3) # scaling parameter\n",
    "inv_2h2 = 1 / (2 * h**2) # 1/(2*h^2)\n",
    "Wmx=np.array([0]) # Wmx0 = (h**2-Nxa) / (h**2) which is essentially 0 for Nxa=3, h=sqrt(3)\n",
    "Wmx=np.append(Wmx,[inv_2h2]*(2*Nxa)) # Wmxi = 1/(2*h^2) for i=1,...,2*Nxa\n",
    "rtWmx=np.sqrt(Wmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05b37b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "SigmaW=.1 # Process noise standard deviation\n",
    "SigmaV=.1 # Measurement noise standard deviation\n",
    "maxIter=4000 # Number of iterations\n",
    "xtrue=2+np.random.normal(0,1) # Initial true state\n",
    "xhat=0 # Initial state estimate\n",
    "# print(xhat)\n",
    "Sigmax=1 # Initial state covariance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a8476ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "xstore=np.zeros(maxIter+1) # Store true states\n",
    "xstore[0]=xtrue\n",
    "xhatstore=np.zeros(maxIter+1) # Store state estimates\n",
    "xhatstore[0]=xhat\n",
    "Sigmaxstore=np.zeros(maxIter+1) # Store state covariance estimates\n",
    "Sigmaxstore[0]=Sigmax\n",
    "# print(xhat)\n",
    "# print(np.array([xhat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d306bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xhat)\n",
    "for k in range(maxIter):\n",
    "    # print(k)\n",
    "    # print(xhat)\n",
    "    xhata=np.array(xhat)\n",
    "    # print(xhata)\n",
    "    xhata=np.append(xhata,[0,0]).reshape(-1,1) # Augmented state vector\n",
    "    # print(xhata)\n",
    "    Sigmaxa=block_diag(Sigmax,SigmaW,SigmaV) # Augmented state covariance\n",
    "    # print(Sigmaxa)\n",
    "    #cholesky decomposition with lower triangular matrix\n",
    "    try: #robustness for non-positive definite matrix\n",
    "        sSigmaxa = cholesky(Sigmaxa, lower=True) \n",
    "    except np.linalg.LinAlgError:\n",
    "        sSigmaxa = np.eye(Sigmaxa.shape[0]) * 1e-6  # fallback\n",
    "    # print(sSigmaxa)\n",
    "    #calculate sigma points\n",
    "    X=np.zeros((Nxa,2*Nxa+1)) # Sigma points matrix\n",
    "    X[:,0]=xhata[:,0] # First sigma point\n",
    "    for i in range(Nxa):\n",
    "        X[:,i+1]=xhata[:,0]+h*sSigmaxa[:,i] # Sigma points for xhat + h*sqrt(Sigmaxa)\n",
    "        X[:,i+1+Nxa]=xhata[:,0]-h*sSigmaxa[:,i] # Sigma points for xhat - h*sqrt(Sigmaxa)\n",
    "    Xx=np.sqrt(5+X[0,:])+X[1,:] # Propagate sigma points through state equation\n",
    "    result=np.sum(Wmx*Xx) # Predicted state mean\n",
    "    # print(result)\n",
    "    xhat=result\n",
    "    Xs=(Xx-xhat)*rtWmx \n",
    "    Sigmax=np.sum(Xs**2) # Predicted state covariance\n",
    "    # print(result1)\n",
    "    w=np.random.normal(0,math.sqrt(SigmaW)) # Process noise\n",
    "    v=np.random.normal(0,math.sqrt(SigmaV)) # Measurement noise\n",
    "    ytrue=xtrue**3+v # True measurement\n",
    "    xtrue=math.sqrt(5+xtrue)+w # True state\n",
    "    \n",
    "    # Y=[Xx[i]**3+X[2,i] for i in range(len(Xx))] # old way\n",
    "    Y=Xx**3+X[2,:] # Propagate sigma points through measurement equation\n",
    "    # print(Y)\n",
    "    result2=np.sum(Wmx*Y)\n",
    "    yhat=result2 # Predicted measurement mean\n",
    "    # print(yhat)\n",
    "    #Ys=np.array([((Y-yhat)*rtWmx) for i in range(len(Y))]) # old way\n",
    "    Ys=(Y-yhat)*rtWmx\n",
    "    result2=np.sum(Ys**2)\n",
    "    SigmaY=result2 # Predicted measurement covariance\n",
    "    # print(result2)\n",
    "    # print(len(Xs),len(Ys))\n",
    "    SigmaXY=np.sum(Xs*Ys) # Cross covariance between state and measurement\n",
    "    # print(SigmaXY)\n",
    "    K=SigmaXY/SigmaY # Kalman gain\n",
    "    # print(K)\n",
    "    xhat=xhat+K*(ytrue-yhat) # Updated state estimate\n",
    "    Sigmax=Sigmax-K*SigmaY*K # Updated state covariance estimate\n",
    "    xstore[k+1]=xtrue # Store true state\n",
    "    xhatstore[k+1]=xhat # Store state estimate\n",
    "    Sigmaxstore[k+1]=Sigmax # Store state covariance estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7d935b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m xresidual=\u001b[43mxstore\u001b[49m-xhatstore\n\u001b[32m      2\u001b[39m resmean=np.mean(xresidual)\n\u001b[32m      3\u001b[39m resstd=np.std(xresidual)\n",
      "\u001b[31mNameError\u001b[39m: name 'xstore' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "xresidual=xstore-xhatstore\n",
    "resmean=np.mean(xresidual)\n",
    "resstd=np.std(xresidual)\n",
    "resskew=stats.skew(xresidual)\n",
    "reskurt=stats.kurtosis(xresidual)\n",
    "meanxstore=np.mean(xstore)\n",
    "meanxhatstore=np.mean(xhatstore)\n",
    "meanSigmaxstore=np.mean(Sigmaxstore)\n",
    "print('Residual Mean:', resmean)\n",
    "print('Residual Std Dev:', resstd)\n",
    "print('Residual Skewness:', resskew)\n",
    "print('Residual Kurtosis:', reskurt)\n",
    "print(f\"mean xstore: {meanxstore}\")\n",
    "print(f\"mean xhatstore: {meanxhatstore}\")\n",
    "print(f\"mean Sigmaxstore: {meanSigmaxstore}\")\n",
    "\n",
    "plt.figure()\n",
    "sns.histplot(xresidual,kde=True, stat=\"density\",bins=50,color='purple', edgecolor='black', label='Residuals')\n",
    "plt.axvline(resmean, color='red', linestyle='dashed', linewidth=1, label='Mean')\n",
    "plt.title('Histogram of Residuals')\n",
    "plt.xlabel('Residual Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "stats.probplot(xresidual, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot of Residuals\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "params = stats.skewnorm.fit(xresidual)\n",
    "x = np.linspace(min(xresidual), max(xresidual), 100)\n",
    "pdf = stats.skewnorm.pdf(x, *params)\n",
    "plt.plot(x, pdf, label=\"Fitted Skew-Normal\", color='orange')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(xresidual,label='Estimation Error',color='red')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(xstore,label='True State')\n",
    "plt.plot(xhatstore,label='Estimated State')\n",
    "plt.fill_between(np.arange(len(Sigmaxstore)),xhatstore-3*np.sqrt(Sigmaxstore),xhatstore+3*np.sqrt(Sigmaxstore),alpha=0.4,label='Uncertainty')\n",
    "plt.ylabel('State Value')\n",
    "plt.title('UKF State Estimation')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
